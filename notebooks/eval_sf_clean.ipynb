{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7588133c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SHALLOW_FUSION_EVAL', 'SF_EVAL', '.models']\n"
     ]
    }
   ],
   "source": [
    "import os, glob, librosa, numpy as np, torch, json\n",
    "from pathlib import Path\n",
    "\n",
    "CACHE_DIR = (Path.cwd().parent / \".models\").resolve()\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "os.environ[\"HF_HUB_DISABLE_XET\"] = \"1\"\n",
    "os.environ[\"HF_HOME\"] = str(CACHE_DIR)\n",
    "print(str(CACHE_DIR).split('/')[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391f466e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "3be2e8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    WhisperProcessor, WhisperForConditionalGeneration,\n",
    "    GPT2LMHeadModel, AutoTokenizer\n",
    ")\n",
    "\n",
    "SR = 16_000\n",
    "BATCH_SIZE = 5\n",
    "WHISPER_ID = \"openai/whisper-small.en\"\n",
    "GPT2_ID = \"cwestnedge/gpt2-small-pubmed\"\n",
    "\n",
    "MANIFEST = \"../data/output/manifest.jsonl\"\n",
    "AUDIO_DIR = \"../data/output\"  \n",
    "\n",
    "DEVICE = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    ")\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d8f72bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257 50256 50257\n"
     ]
    }
   ],
   "source": [
    "# fast tokenizers will show token mismatch between models and will be auto loaded when we run on colab A100 set flag to false to avoid annoyingness\n",
    "processor = WhisperProcessor.from_pretrained(WHISPER_ID, cache_dir=CACHE_DIR, use_fast=False)\n",
    "whisper = WhisperForConditionalGeneration.from_pretrained(WHISPER_ID, cache_dir=CACHE_DIR).to(DEVICE).eval()\n",
    "\n",
    "gpt2_tok = AutoTokenizer.from_pretrained(GPT2_ID, cache_dir=CACHE_DIR, use_fast=False)\n",
    "gpt2 = GPT2LMHeadModel.from_pretrained(GPT2_ID, cache_dir=CACHE_DIR).to(DEVICE).eval()\n",
    "\n",
    "if gpt2_tok.pad_token is None:\n",
    "    gpt2_tok.add_special_tokens({\"pad_token\": \"<|pad|>\"})\n",
    "    gpt2.resize_token_embeddings(len(gpt2_tok))\n",
    "\n",
    "PAD_ID = gpt2_tok.pad_token_id # e.g. 50257\n",
    "EOS_ID = gpt2_tok.eos_token_id # 50256 (unchanged)\n",
    "SHARED_VOCAB = EOS_ID + 1\n",
    "\n",
    "print(PAD_ID, EOS_ID, SHARED_VOCAB)\n",
    "# 50257 50256 50257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5188f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(SHARED_VOCAB):\n",
    "#   a = processor.tokenizer.decode([i])\n",
    "#   b = gpt2_tok.decode([i])\n",
    "#   if a != b:\n",
    "#     print(f\"Token mismatch at index {i}\\nwhisper token: {a}\\n   gpt2 token: {b} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "be085a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 100/100 [00:07<00:00, 13.11 examples/s]\n",
      "Map: 100%|██████████| 20/20 [00:01<00:00, 17.39 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(manifest_path: str, batch_size: int, num_proc: int = 4) -> Dataset:\n",
    "    with open(manifest_path, encoding=\"utf-8\") as f:\n",
    "        rows = [json.loads(line) for line in f]\n",
    "\n",
    "    ds = Dataset.from_list(rows)\n",
    "\n",
    "    def add_audio(batch):\n",
    "        batch[\"audio\"] = [\n",
    "            librosa.load(f\"{AUDIO_DIR}/{fname}\", sr=SR, mono=True)[0].astype(np.float32)\n",
    "            for fname in batch[\"file\"]\n",
    "        ]\n",
    "        return batch\n",
    "\n",
    "    return ds.map(add_audio, batched=True, batch_size=batch_size, num_proc=num_proc)\n",
    "\n",
    "def encode_audio(batch):\n",
    "    # batch[\"audio\"] is List[np.ndarray], each at its natural length\n",
    "    feats = processor.feature_extractor(\n",
    "        batch[\"audio\"], # for whatever reason processor doesnt support PT tensors so numpy array or list for now.\n",
    "        sampling_rate=SR,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True, \n",
    "        max_length=processor.feature_extractor.n_samples,  # n_samples = chunk_length * sampling_rate\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\" \n",
    "    )\n",
    "\n",
    "    #  input_features : Tensor (B, T_max, 80)\n",
    "    #  attention_mask : Tensor (B, T_max)\n",
    "    batch[\"input_features\"] = feats.input_features\n",
    "    batch[\"attention_mask\"] = feats.attention_mask\n",
    "    return batch\n",
    "\n",
    "ds = build_dataset(MANIFEST, batch_size=BATCH_SIZE).select(range(20))\n",
    "\n",
    "# choosing NOT to overwrite ds with removed fields so we can eval on text field later,\n",
    "# could also create a collator and pass fields we care about through, but seems like \n",
    "# too much extra code tbh, indices will still match if we dont shuffle\n",
    "ds_processed = ds.map(\n",
    "    encode_audio, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    batched=True,\n",
    "    remove_columns=['uuid', 'file', 'chunk_id', 'orig_id', 'label', 'text', 'audio']\n",
    "    )\n",
    "\n",
    "ds_processed.set_format(type=\"torch\", columns=[\"input_features\",\"attention_mask\"])\n",
    "loader = DataLoader(ds_processed, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "629e3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _hyphen_ids(tok, vocab_limit):\n",
    "#     # any ASCII hyphen or Unicode dash char\n",
    "#     dash_chars = {\"-\", \"-\", \"–\", \"—\"}\n",
    "#     return torch.tensor(\n",
    "#         [i for i in range(vocab_limit)\n",
    "#          if any(ch in tok.decode([i]) for ch in dash_chars)],\n",
    "#         dtype=torch.long\n",
    "#     )\n",
    "\n",
    "# HYPHEN_IDS = _hyphen_ids(gpt2_tok, len(gpt2_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "08b3ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LogitsProcessor\n",
    "\n",
    "class ShallowFusion(LogitsProcessor):\n",
    "    def __init__(self, lm, fusion_exclusive, pad_id, alpha=0.3, warmup_steps=3, temperature=0.05):\n",
    "        super().__init__()\n",
    "        self.lm = lm.eval().requires_grad_(False)\n",
    "        self.fusion_excl = fusion_exclusive  # e.g. EOS_ID = 50256\n",
    "        self.pad_id = pad_id\n",
    "        self.alpha = alpha\n",
    "        self.warmup = warmup_steps\n",
    "        self.temp = temperature\n",
    "        self.step = 0\n",
    "        self.alpha_scale = 0.35\n",
    "        self.entropy_threshold = 1.3\n",
    "    \n",
    "    def reset(self):\n",
    "        self.step = 0\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def __call__(self, input_ids, scores):\n",
    "        w_lp = torch.log_softmax(scores, dim=-1)\n",
    "\n",
    "        if self.step < self.warmup: \n",
    "            self.step+=1 \n",
    "            return w_lp\n",
    "        self.step+=1 \n",
    "\n",
    "        # ----DYNAMIC ALPHA------\n",
    "        # w_probs = w_lp.exp()\n",
    "        # # Compute entropy safely: ignore zero probabilities\n",
    "        # ent_contrib = torch.where(w_probs > 0,\n",
    "        #                           w_probs * w_lp,\n",
    "        #                           torch.zeros_like(w_lp))\n",
    "        # w_entropy = -(ent_contrib.sum(dim=-1, keepdim=True))  # shape: [B,1]\n",
    "        # # Smooth gating: map entropy to [alpha, alpha*alpha_scale]\n",
    "        # gate = torch.sigmoid((w_entropy - self.entropy_threshold) * 2)\n",
    "        # ----DYNAMIC ALPHA------\n",
    "\n",
    "        # replace OOV tokens with pad tokens and exclude from attention scores\n",
    "        # fuse [0 … EOS_ID-1], leave EOS untouched\n",
    "\n",
    "        oob_mask = input_ids > self.fusion_excl\n",
    "        filtered_ids = input_ids.masked_fill(oob_mask, self.pad_id)\n",
    "        attn_mask = (filtered_ids != self.pad_id).long()\n",
    "\n",
    "        lm_logits = self.lm(\n",
    "            input_ids=filtered_ids, \n",
    "            attention_mask=attn_mask\n",
    "        ).logits[:,-1,:] # only want logits for next token\n",
    "        lm_lp = torch.log_softmax(lm_logits, dim=-1)[:, :self.fusion_excl]\n",
    "\n",
    "        fused_slice = w_lp[:, :self.fusion_excl] + self.alpha * lm_lp\n",
    "        fused_lp = w_lp.clone()\n",
    "        fused_lp[:, :self.fusion_excl] = fused_slice\n",
    "        \n",
    "        # renormalize\n",
    "        fused_lp -= torch.logsumexp(fused_lp, dim=-1, keepdim=True)\n",
    "        \n",
    "        return fused_lp # / self.temp\n",
    "    \n",
    "fusion_proc = ShallowFusion(\n",
    "    lm=gpt2,\n",
    "    fusion_exclusive=EOS_ID, # e.g. EOS_ID = 50256\n",
    "    pad_id=PAD_ID,# <— 50257\n",
    "    alpha=0.2,\n",
    "    warmup_steps=4,\n",
    "    temperature = 1.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2dfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding:  25%|██▌       | 1/4 [01:55<05:46, 115.37s/it]"
     ]
    }
   ],
   "source": [
    "from transformers import LogitsProcessorList\n",
    "from tqdm import tqdm \n",
    "\n",
    "fused = []\n",
    "refs = []\n",
    "\n",
    "for idx, batch in enumerate(tqdm(loader, total=len(loader), desc=\"Decoding\")):\n",
    "    feats = batch['input_features'].to(DEVICE)\n",
    "    masks = batch['attention_mask'].to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fused_ids = whisper.generate(\n",
    "            input_features=feats,\n",
    "            attention_mask=masks,\n",
    "            logits_processor=LogitsProcessorList([fusion_proc]),\n",
    "            num_beams=4,\n",
    "            do_sample=False,\n",
    "            length_penalty=1.0,\n",
    "        )\n",
    "    decoded = processor.batch_decode(fused_ids, skip_special_tokens=True)\n",
    "    fused.extend(decoded)\n",
    "    fusion_proc.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3f466239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding: 100%|██████████| 4/4 [00:28<00:00,  7.10s/it]\n"
     ]
    }
   ],
   "source": [
    "class NoOpLogitsProcessor(LogitsProcessor):\n",
    "    \"\"\"\n",
    "    A simple logits processor that performs no modifications to the logits.\n",
    "    \"\"\"\n",
    "    def __call__(self, input_ids, scores):\n",
    "        # Return the scores unchanged\n",
    "\n",
    "        w_lp = torch.log_softmax(scores, dim=-1)\n",
    "        return w_lp\n",
    "\n",
    "\n",
    "noop_processor = NoOpLogitsProcessor()\n",
    "vanilla = []\n",
    "\n",
    "for idx, batch in enumerate(tqdm(loader, total=len(loader), desc=\"Decoding\")):\n",
    "    feats = batch['input_features'].to(DEVICE)\n",
    "    masks = batch['attention_mask'].to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        vanilla_ids = whisper.generate(\n",
    "            input_features=feats,\n",
    "            attention_mask=masks,\n",
    "            logits_processor=LogitsProcessorList([noop_processor]),\n",
    "            num_beams=1,\n",
    "            do_sample=False,\n",
    "            length_penalty=1.0,\n",
    "        )\n",
    "    decoded = processor.batch_decode(vanilla_ids, skip_special_tokens=True)\n",
    "    vanilla.extend(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f06c8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        \"vanilla\":[i.strip() for i in vanilla], \n",
    "        \"fused\":[i.strip() for i in fused], \n",
    "        \"reference\":ds['text'],\n",
    "        # \"medical_terms\":ds['medical_terms']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3afaf542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base  WER (punct-insensitive): 0.04469273107353603\n",
      "Fused WER (punct-insensitive): 0.05052003122436559\n"
     ]
    }
   ],
   "source": [
    "from jiwer import (\n",
    "    Compose,\n",
    "    ToLowerCase,\n",
    "    RemovePunctuation,\n",
    "    RemoveMultipleSpaces,\n",
    "    Strip,\n",
    "    ReduceToListOfListOfWords,\n",
    "    wer\n",
    ")\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "\n",
    "# helper to handle both str and list[str]\n",
    "def _map(func, x):\n",
    "    return [func(t) for t in x] if isinstance(x, list) else func(x)\n",
    "\n",
    "def remove_diacritics(x):\n",
    "    return _map(unidecode, x)\n",
    "\n",
    "def split_hyphens_and_slashes(x):\n",
    "    # replace any dash or slash with a space so we never glue words together\n",
    "    return _map(lambda t: re.sub(r\"[-–—/]\", \" \", t), x)\n",
    "\n",
    "def normalize_nums(x):\n",
    "    # unify 12–16 → 12-16\n",
    "    return _map(lambda t: re.sub(r\"(\\d)[-–—-](\\d)\", r\"\\1-\\2\", t), x)\n",
    "\n",
    "transform = Compose([\n",
    "    ToLowerCase(),\n",
    "    remove_diacritics,\n",
    "    split_hyphens_and_slashes,    # ← split first\n",
    "    normalize_nums,\n",
    "    RemovePunctuation(),           # now drop commas, periods, etc.\n",
    "    RemoveMultipleSpaces(),\n",
    "    Strip(),\n",
    "    ReduceToListOfListOfWords(),   # produce [[“word”,…],…]\n",
    "])\n",
    "\n",
    "def compute_wer(ref, hyp):\n",
    "    return wer(\n",
    "        ref, hyp,\n",
    "        reference_transform=transform,\n",
    "        hypothesis_transform=transform,\n",
    "    )\n",
    "\n",
    "# rename & score\n",
    "results_df = results_df.rename(columns={\"gt\": \"reference\"})\n",
    "results_df[\"wer_base\"]  = results_df.apply(\n",
    "    lambda r: compute_wer(r[\"reference\"], r[\"vanilla\"]), axis=1\n",
    ")\n",
    "results_df[\"wer_fused\"] = results_df.apply(\n",
    "    lambda r: compute_wer(r[\"reference\"], r[\"fused\"]), axis=1\n",
    ")\n",
    "\n",
    "print(\"Base  WER (punct-insensitive):\", results_df[\"wer_base\"].mean())\n",
    "print(\"Fused WER (punct-insensitive):\", results_df[\"wer_fused\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c1ac6469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vanilla</th>\n",
       "      <th>fused</th>\n",
       "      <th>reference</th>\n",
       "      <th>wer_base</th>\n",
       "      <th>wer_fused</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>He smokes two packs a day and he has two beers...</td>\n",
       "      <td>He smokes two packs a day and he has two beers...</td>\n",
       "      <td>He smokes two packs a day and he has two beers...</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.096154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the inferior pole of the right kidney. There i...</td>\n",
       "      <td>the inferior pole of the right kidney. There i...</td>\n",
       "      <td>the inferior pole of the right kidney. There i...</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>With diverticulitis, no pneumoperatinin is ide...</td>\n",
       "      <td>With diverticulitis, no pneumoperitoneum is id...</td>\n",
       "      <td>with diverticulitis. No pneumoperitoneum is id...</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stomach, it was insufflated and the scope was ...</td>\n",
       "      <td>Stomach, it was inseflated and the scope was c...</td>\n",
       "      <td>stomach. It was insufflated and the scope was ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IV Demerol and Versed for sedation. When adequ...</td>\n",
       "      <td>IV Demerol and versed for sedation. When adequ...</td>\n",
       "      <td>IV Demerol and Versed for sedation. When adequ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1. Lisinopril 2. Metaprolol 3. Vitamin B12 4. ...</td>\n",
       "      <td>1. Lisinopril 2. Metaprolol 3. Vitamin B12 4. ...</td>\n",
       "      <td>1. Lisinopril. 2. Metoprolol. 3. Vitamin B12. ...</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>administered. The lung bases are clear. The li...</td>\n",
       "      <td>administered. The lung bases are clear. The li...</td>\n",
       "      <td>administered. The lung bases are clear. The li...</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gidney, adrenal, abdomen and pelvis, CT scan, ...</td>\n",
       "      <td>Gidney, adrenal, abdomen and pelvis, CT scan, ...</td>\n",
       "      <td>kidney, adrenal, abdomen and pelvis, ct scan, ...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bumped his head once, but not his chest, altho...</td>\n",
       "      <td>bumped his head once, but not his chest, altho...</td>\n",
       "      <td>bumped his head once, but not his chest, altho...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>chest pain, SOB, supine, palpitations, edema, ...</td>\n",
       "      <td>chest pain, S.O.B., supine, palpitations, edem...</td>\n",
       "      <td>chest pain, SOB supine, palpitations, edema, v...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              vanilla  \\\n",
       "16  He smokes two packs a day and he has two beers...   \n",
       "3   the inferior pole of the right kidney. There i...   \n",
       "5   With diverticulitis, no pneumoperatinin is ide...   \n",
       "7   Stomach, it was insufflated and the scope was ...   \n",
       "8   IV Demerol and Versed for sedation. When adequ...   \n",
       "18  1. Lisinopril 2. Metaprolol 3. Vitamin B12 4. ...   \n",
       "1   administered. The lung bases are clear. The li...   \n",
       "0   Gidney, adrenal, abdomen and pelvis, CT scan, ...   \n",
       "13  bumped his head once, but not his chest, altho...   \n",
       "17  chest pain, SOB, supine, palpitations, edema, ...   \n",
       "\n",
       "                                                fused  \\\n",
       "16  He smokes two packs a day and he has two beers...   \n",
       "3   the inferior pole of the right kidney. There i...   \n",
       "5   With diverticulitis, no pneumoperitoneum is id...   \n",
       "7   Stomach, it was inseflated and the scope was c...   \n",
       "8   IV Demerol and versed for sedation. When adequ...   \n",
       "18  1. Lisinopril 2. Metaprolol 3. Vitamin B12 4. ...   \n",
       "1   administered. The lung bases are clear. The li...   \n",
       "0   Gidney, adrenal, abdomen and pelvis, CT scan, ...   \n",
       "13  bumped his head once, but not his chest, altho...   \n",
       "17  chest pain, S.O.B., supine, palpitations, edem...   \n",
       "\n",
       "                                            reference  wer_base  wer_fused  \\\n",
       "16  He smokes two packs a day and he has two beers...  0.019231   0.115385   \n",
       "3   the inferior pole of the right kidney. There i...  0.060000   0.100000   \n",
       "5   with diverticulitis. No pneumoperitoneum is id...  0.080000   0.060000   \n",
       "7   stomach. It was insufflated and the scope was ...  0.000000   0.020000   \n",
       "8   IV Demerol and Versed for sedation. When adequ...  0.000000   0.020000   \n",
       "18  1. Lisinopril. 2. Metoprolol. 3. Vitamin B12. ...  0.060000   0.040000   \n",
       "1   administered. The lung bases are clear. The li...  0.058824   0.039216   \n",
       "0   kidney, adrenal, abdomen and pelvis, ct scan, ...  0.111111   0.111111   \n",
       "13  bumped his head once, but not his chest, altho...  0.000000   0.000000   \n",
       "17  chest pain, SOB supine, palpitations, edema, v...  0.000000   0.000000   \n",
       "\n",
       "        diff  \n",
       "16  0.096154  \n",
       "3   0.040000  \n",
       "5   0.020000  \n",
       "7   0.020000  \n",
       "8   0.020000  \n",
       "18  0.020000  \n",
       "1   0.019608  \n",
       "0   0.000000  \n",
       "13  0.000000  \n",
       "17  0.000000  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['diff'] = abs(results_df.wer_base - results_df.wer_fused)\n",
    "top_diffs = results_df.sort_values(by='diff', ascending=False).head(10)\n",
    "top_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "87f577d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GT:    kidney, adrenal, abdomen and pelvis, ct scan, intravenous, abdomen,\n",
      "Base:  Gidney, adrenal, abdomen and pelvis, CT scan, intravenous, abdomen.\n",
      "Fused: Gidney, adrenal, abdomen and pelvis, CT scan, intravenous, abdomen.\n",
      "\n",
      "GT:    administered. The lung bases are clear. The liver is enlarged and decreased in attenuation. There are no focal liver masses. There is no intra or extrahepatic ductal dilatation. The gallbladder is slightly distended. The adrenal glands, pancreas, spleen, and left kidney are normal. A 12-mm simple cyst is present in\n",
      "Base:  administered. The lung bases are clear. The liver is enlarged and decreased in attenuation. There are no focal liver masses. There's no intra or extrahepatic ductal dilatation. The gallbladder is slightly distended. The adrenal glands, pancreas, spleen, and left kidney are normal. A 12 millimeter simple cyst is present in.\n",
      "Fused: administered. The lung bases are clear. The liver is enlarged and decreased in attenuation. There are no focal liver masses. There is no intra or extra hepatic ductal dilatation. The gallbladder is slightly distended. The adrenal glands, pancreas, spleen, and left kidney are normal. A 12-mm simple cyst is present in\n",
      "\n",
      "GT:    Exam: CT scan of the abdomen and pelvis without and with intravenous contrast. Clinical Indication: Left lower quadrant abdominal pain. Comparison: None. Findings: CT scan of the abdomen and pelvis was performed without and with intravenous contrast. Total of 100 mL of Isovue was administered intravenously. Oral contrast was also\n",
      "Base:  Exam CT scan of the abdomen and pelvis without and with intravenous contrast. Clinical indication left lower quadrant abdominal pain. Comparison, none. Findings. CT scan of the abdomen and pelvis was performed without and with intravenous contrast. Total of 100 milliliters of isovu was administered intravenously. Oral contrast was also\n",
      "Fused: Exam CT scan of the abdomen and pelvis without and with intravenous contrast. Clinical indication, left lower quadrant abdominal pain. Comparison, none. Findings, CT scan of the abdomen and pelvis was performed without and with intravenous contrast. Total of 100 milliliters of isovu was administered intravenously. Oral contrast was also\n",
      "\n",
      "GT:    the inferior pole of the right kidney. There is no hydronephrosis or hydroureter. The appendix is normal. There are multiple diverticula in the rectosigmoid. There is evidence of focal wall thickening in the sigmoid colon (image #69) with adjacent fat stranding in association with a diverticulum. These findings are consistent\n",
      "Base:  the inferior pole of the right kidney. There is no hydroinophrosis or hydrouritor. The appendix is normal. There are multiple diverticula in the rectosigmoid. There is evidence of focal wall thickening in the sigmoid colon, image number 69, with adjacent fat stranding in association with a diverticulum. These findings are consistent.\n",
      "Fused: the inferior pole of the right kidney. There is no hydro-naphrosis or hydro-uridor. The appendix is normal. There are multiple diverticula in the rectosigmoid. There is evidence of focal wall thickening in the sigmoid colon, image number 69, with adjacent fat stranding in association with a diverticulum. These findings are consistent\n",
      "\n",
      "GT:    and GERD type symptoms including complications such as hoarseness and chronic cough. She has been on multiple medical regimens and continues with dyspeptic symptoms. Procedure: After proper informed consent was obtained, the patient was brought to the endoscopy suite. She was placed in the left lateral position and was given\n",
      "Base:  and GERD-type symptoms, including complications such as hoarseness and chronic cough. She has been on multiple medical regimens and continues with dyspeptic symptoms. Procedure, after proper informed consent was obtained, the patient was brought to the endoscopy suite. She was placed in the left lateral position and was given.\n",
      "Fused: and GERD-type symptoms, including complications such as hoarseness and chronic cough. She has been on multiple medical regimens and continues with dyspeptic symptoms. Procedure, after proper informed consent was obtained, the patient was brought to the endoscopy suite. She was placed in the left lateral position and was given.\n",
      "\n",
      "GT:    with diverticulitis. No pneumoperitoneum is identified. There is no ascites or focal fluid collection. The aorta is normal in contour and caliber. There is no adenopathy. Degenerative changes are present in the lumbar spine. Impression: Findings consistent with diverticulitis. Please see report above.gastroenterology, extrahepatic ductal dilatation, gallbladder, glands, pancreas, spleen,\n",
      "Base:  With diverticulitis, no pneumoperatinin is identified. There is no ascites or focal fluid collection. The aorta is normal in contour and caliber. There is no adenopathy. Degenerative changes are present in the lumbar spine. Impression. Findings consistent with diverticulitis. Please see report above. Gastroenterology. Extrahepatic ductal dilatation. Gallbladder. Glans. Pancreas. Spleen.\n",
      "Fused: With diverticulitis, no pneumoperitoneum is identified. There is no ascites or focal fluid collection. The aorta is normal in contour and caliber. There is no adenopathy. Degenerative changes are present in the lumbar spine. Impression. Findings consistent with diverticulitis. Please see report above. Gastroenterology. Extrahepatic ductal dilatation. Gallbladder. Glans. Pancreas. Spleen.\n",
      "\n",
      "GT:    Preoperative Diagnosis: Refractory dyspepsia. Postoperative Diagnosis: 1. Hiatal hernia. 2. Reflux esophagitis. Procedure Performed: Esophagogastroduodenoscopy with pseudo and esophageal biopsy. Anesthesia: Conscious sedation with Demerol and Versed. Specimen: Esophageal biopsy. Complications: None. History: The patient is a 52-year-old female morbidly obese black female who has a long history of reflux\n",
      "Base:  preoperative diagnosis, refractory dyspepsia, postoperative diagnosis. One, hiatal hernia. Two, reflux esophagitis, procedure performed, esophagogastroduodenoscopy with pseudo and esophageal biopsy. Anesthesia, conscious sedation with demerol and verced. Specimen, esophageal biopsy. Complications, none. History, the patient is a 52-year-old female, morbidly obese black female who has a long history of reflux.\n",
      "Fused: preoperative diagnosis, refractory dyspepsia, postoperative diagnosis. One, hiatal hernia. Two, reflux esophagitis. Procedure performed, esophagogastroduodenoscopy with pseudo and esophageal biopsy. Anesthesia, conscious sedation with demerol and verced. Specimen, esophageal biopsy. Complications, none. History, the patient is a 52-year-old female, morbidly obese, black female who has a long history of reflux.\n",
      "\n",
      "GT:    stomach. It was insufflated and the scope was coursed along the greater curvature to the antrum. The pylorus was patent. There was evidence of bile reflux in the antrum. The duodenal bulb and sweep were examined and were without evidence of mass, ulceration, or inflammation. The scope was then brought\n",
      "Base:  Stomach, it was insufflated and the scope was coursed along the greater curvature to the antrum. The pylorus was patent. There was evidence of bile reflux in the antrum. The duodenal bulb and sweep were examined and were without evidence of mass, ulceration, or inflammation. The scope was then brought.\n",
      "Fused: Stomach, it was inseflated and the scope was coursed along the greater curvature to the antrum. The pylorus was patent. There was evidence of bile reflux in the antrum. The duodenal bulb and sweep were examined and were without evidence of mass, ulceration, or inflammation. The scope was then brought.\n",
      "\n",
      "GT:    IV Demerol and Versed for sedation. When adequate level of sedation achieved, the gastroscope was inserted into the hypopharynx and the esophagus was easily intubated. At the GE junction, a hiatal hernia was present. There were mild inflammatory changes consistent with reflux esophagitis. The scope was then passed into the\n",
      "Base:  IV Demerol and Versed for sedation. When adequate level of sedation achieved, the gastroscope was inserted into the hypopharynx, and the esophagus was easily intubated. At the GE junction, a hiatal hernia was present. There were mild inflammatory changes consistent with reflux esophagitis. The scope was then passed into the\n",
      "Fused: IV Demerol and versed for sedation. When adequate level of sedation achieved, the gastricoscope was inserted into the hypopharynx, and the esophagus was easily intubated. At the GE junction, a hiatal hernia was present. There were mild inflammatory changes consistent with reflux esophagitis. The scope was then passed into the\n",
      "\n",
      "GT:    back into the antrum. A retroflexion was attempted multiple times, however, the patient was having difficulty holding the air and adequate retroflexion view was not visualized. The gastroscope was then slowly withdrawn. There were no other abnormalities noted in the fundus or body. Once again at the GE junction, esophageal\n",
      "Base:  Back into the antrum, a retroflexion was attempted multiple times. However, the patient was having difficulty holding the air and adequate retroflexion view was not visualized. The gastroscope was then slowly withdrawn. There were no other abnormalities noted in the fundus or body. Once again at the GE junction, esophageal.\n",
      "Fused: Back into the antrum, a retroflexion was attempted multiple times. However, the patient was having difficulty holding the air and adequate retroflexion. View was not visualized. The gastroscope was then slowly withdrawn. There were no other abnormalities noted in the fundus or body. Once again, at the GE junction, esophageal.\n",
      "\n",
      "GT:    loss.gastroenterology, refractory dyspepsia, hiatal hernia, reflux esophagitis, esophagogastroduodenoscopy, esophageal, pseudo, esophageal biopsy, ge junction, hiatal, hernia, esophagitis, antrum, gerd,\n",
      "Base:  Lusst.gastroenterology, refractory dyspepsia, hiatal hernia, reflux esophagitis, esomego-gastro duodenoscopy, esophageal, pseudo, esophageal biopsy, GE junction, hiatal hernia, esophagitis, antrum, GERD.\n",
      "Fused: Lusst.gastroenterology, refractory dyspepsia, hiatal hernia, reflux esophagitis, esomego-gastro-duodenoscopy, esophageal, pseudo-esophageal biopsy, GE junction, hiatal hernia, esophagitis, antrum, GERD.\n",
      "\n",
      "GT:    Chief Complaint: Lump in the chest wall. History Of Present Illness: This is a 56-year-old white male who has been complaining of having had a lump in the chest for the past year or so and it has been getting larger and tender according to the patient. It is tender\n",
      "Base:  Chief Complaint, Lump in the Chest Wall. History of Present Illness. This is a 56-year-old white male who has been complaining of having had a lump in the chest for the past year or so, and it has been getting larger and tender, according to the patient. It is tender.\n",
      "Fused: Chief Complaint, Lump in the Chest Wall. History of present illness. This is a 56-year-old white male who has been complaining of having had a lump in the chest for the past year or so, and it has been getting larger and tender, according to the patient. It is tender.\n",
      "\n",
      "GT:    biopsy was taken. The scope was then completely withdrawn. The patient tolerated the procedure and was transferred to the recovery room in stable condition. She will return to the General Medical Floor. We will continue b.i.d proton-pump inhibitor therapy as well as dietary restrictions. She should also attempt significant weight\n",
      "Base:  biopsy was taken. The scope was then completely withdrawn. The patient tolerated the procedure and was transferred to the recovery room in stable condition. She will return to the general medical floor. We will continue BID, proton pump inhibitor therapy, as well as dietary restrictions. She should also attend significant weight.\n",
      "Fused: biopsy was taken. The scope was then completely withdrawn. The patient tolerated the procedure and was transferred to the recovery room in stable condition. She will return to the general medical floor. We will continue BID, proton pump inhibitor therapy, as well as dietary restrictions. She should also attend significant weight.\n",
      "\n",
      "GT:    bumped his head once, but not his chest, although he told the nurse that a car fell on his chest that is six years ago. He told me that he hit a moose once, but he does not remember hitting his chest. Allergies: To Bactrim: Simvastatin: AND CIPRO. Current Medications:\n",
      "Base:  bumped his head once, but not his chest, although he told the nurse that a car fell on his chest that is six years ago. He told me that he hit a moose once, but he does not remember hitting his chest. Allergies, to Bactrim, Simvastatin, and Cipro. Current medications.\n",
      "Fused: bumped his head once, but not his chest, although he told the nurse that a car fell on his chest that is six years ago. He told me that he hit a moose once, but he does not remember hitting his chest. Allergies, to bactrim, simvastatin, and cipro. Current medications.\n",
      "\n",
      "GT:    hand surgery, colonoscopy, arm nerve surgery, and back surgery. Previous Injuries: He had a broken ankle in the past. They questioned the patient who is a truck driver whether he has had an auto accident in the past, he said that he has not had anything major. He said he\n",
      "Base:  hand surgery, colonoscopy, arm nerve surgery, and back surgery. Previous Injuries He had a broken ankle in the past. They questioned the patient who is a truck driver whether he has had an auto accident in the past. He said that he has not had anything major. He said he.\n",
      "Fused: hand surgery, colonoscopy, arm-nerve surgery, and back surgery. Previous injuries, he had a broken ankle in the past. They questioned the patient, who is a truck driver, whether he has had an auto accident in the past. He said that he has not had anything major. He said he\n",
      "\n",
      "GT:    on palpation and also he feels like, when he takes a deep breath also, it hurts. Chronic/Inactive Conditions: 1. Hypertension. 2. Hyperlipidemia. 3. Glucose intolerance. 4. Chronic obstructive pulmonary disease?,5. Tobacco abuse. 6. History of anal fistula. Illnesses: See above. Previous Operations: Anal fistulectomy, incision and drainage of perirectal abscess,\n",
      "Base:  on palpation and also he feels like when he takes a deep breath also, it hurts. Chronic inactive conditions, one, hypertension, two, hyperlipidemia, three, glucose intolerance, four, chronic obstructive pulmonary disease, five, tobacco abuse, six, history of anal fistula, illnesses, see above. Previous operations, anal fistullectomy, incision and drainage of perirectal abscess.\n",
      "Fused: on palpation and also he feels like when he takes a deep breath also, it hurts. Chronic inactive conditions, one, hypertension, two, hyperlipidemia, three, glucose intolerance, four, chronic obstructive pulmonary disease, five, tobacco abuse, six, history of anal fistula, illnesses, see above, previous operations, anal fistullectomy, incision and drainage of perirectal abscess.\n",
      "\n",
      "GT:    He smokes two packs a day and he has two beers a day he says, but not consuming illegal drugs. Review Of Systems: Constitutional: Denies weight loss/gain, fever or chills. Enmt: Denies headaches, nosebleeds, voice changes, blurry vision or changes in/loss of vision. Cv: See history of present illness. Denies\n",
      "Base:  He smokes two packs a day and he has two beers a day, he says, but not consuming illegal drugs. Review of systems. Constitutional. Denies weight loss gain, fever or chills. EMT denies headaches, nosebleeds, voice changes, blurry vision or changes in loss of vision. CV. See history of present illness. Denies.\n",
      "Fused: He smokes two packs a day and he has two beers a day, he says, but not consuming illegal drugs. Review of systems, constitutional, denies weight loss gain, fever or chills. E-M-N-T, denies headaches, nosebleeds, voice changes, blurry vision or changes in loss of vision. C-V, see history of present illness, denies.\n",
      "\n",
      "GT:    chest pain, SOB supine, palpitations, edema, varicose veins or leg pains. Respiratory: He has a chronic cough. Denies shortness of breath, wheezing, sputum production or bloody sputum. Gi: Denies heartburn, blood in stools, loss of appetite, abdominal pain or constipation. Gu: Denies painful/burning urination, cloudy/dark urine, flank pain or groin\n",
      "Base:  chest pain, SOB, supine, palpitations, edema, varicose veins, or leg pains. Respiratory, he has a chronic cough. Denies shortness of breath, wheezing, sputum production, or bloody sputum. GI denies heartburn, blood in stools, loss of appetite, abdominal pain, or constipation. GU denies painful burning urination, cloudy dark urine, flank pain, or groin.\n",
      "Fused: chest pain, S.O.B., supine, palpitations, edema, varicose veins, or leg pains. Respiratory, he has a chronic cough. Denies shortness of breath, wheezing, sputum production, or bloody sputum. G.I. denies heartburn, blood in stools, loss of appetite, abdominal pain, or constipation. G.U. denies painful burning urination, cloudy dark urine, flank pain, or groin.\n",
      "\n",
      "GT:    1. Lisinopril. 2. Metoprolol. 3. Vitamin B12. 4. Baby aspirin. 5. Gemfibrozil. 6. Felodipine. 7. Levitra. 8. Pravastatin. Family History: Positive for hypertension, diabetes, and cancer. Negative for heart disease, obesity or stroke. Social History: The patient is married. He works as a truck driver and he drives in town.\n",
      "Base:  1. Lisinopril 2. Metaprolol 3. Vitamin B12 4. Baby Aspirin 5. Gemfibrazil 6. Phylodipine 7. Levitra 8. Pravastatin Family history Positive for hypertension, diabetes, and cancer Negative for heart disease, obesity, or stroke Social history, the patient is married, he works as a truck driver, and he drives in town.\n",
      "Fused: 1. Lisinopril 2. Metaprolol 3. Vitamin B12 4. Baby Aspirin 5. Gemfibrozil 6. Phylodipine 7. Levitra 8. Pravastatin Family history. Positive for hypertension, diabetes, and cancer. Negative for heart disease, obesity, or stroke. Social history. The patient is married. He works as a truck driver, and he drives in town.\n",
      "\n",
      "GT:    the midline, and there are no masses. No crepitus is palpated. The thyroid is palpable, not enlarged, smooth, moves with swallowing, and has no palpable masses. Respiration: Normal respiratory effort. There is no intercostal retraction or action by the accessory muscles. Normal breath sounds bilaterally with no rhonchi, wheezing or\n",
      "Base:  The midline and there are no masses. No crepitus is palpated. The thyroid is palpable, not enlarged, smooth, moves with swallowing and has no palpable masses. Respiration. Normal respiratory effort. There is no intercostal retraction or action by the accessory muscles. Normal breath sounds bilaterally, with no Ronchi wheezing or\n",
      "Fused: The midline and there are no masses. No crepitus is palpated. The thyroid is palpable, not enlarged, smooth, moves with swallowing and has no palpable masses. Respiration. Normal respiratory effort. There is no intercostal retraction or action by the accessory muscles. Normal breath sounds bilaterally, with no ronchi, wheezing, or\n"
     ]
    }
   ],
   "source": [
    "print_str = '''\n",
    "GT:    {}\n",
    "Base:  {}\n",
    "Fused: {}'''\n",
    "\n",
    "for idx, row in results_df.iterrows():\n",
    "    row_str = print_str.format(\n",
    "        row['reference'], \n",
    "        row['vanilla'], \n",
    "        row['fused']\n",
    "    )\n",
    "    print(row_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad32e310",
   "metadata": {},
   "source": [
    "# BONEYARD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "85c8ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =============================================================\n",
    "# #  One-cell evaluation (uses your original jiwer transform)\n",
    "# #  -------------------------------------------------------------\n",
    "# #  Metrics per model:\n",
    "# #    • Global WER                --> same as your old script\n",
    "# #    • Medical-Term Recall (MTR) --> fraction of terms perfectly present\n",
    "# #    • Medical-Term-only WER     --> WER on tokens that belong to terms\n",
    "# #\n",
    "# #  Expects a DataFrame `results_df` with columns:\n",
    "# #        reference, vanilla, fused, medical_terms\n",
    "# #  where medical_terms is list[str]  (or a string repr like \"['a','b']\").\n",
    "# # =============================================================\n",
    "\n",
    "# import re, ast, itertools, pandas as pd\n",
    "# from jiwer import (\n",
    "#     Compose, ToLowerCase, RemovePunctuation, RemoveMultipleSpaces,\n",
    "#     Strip, ReduceToListOfListOfWords, wer\n",
    "# )\n",
    "# from unidecode import unidecode\n",
    "\n",
    "\n",
    "# # ---------- helper to handle both str & list[str] -------------------\n",
    "# def _map(func, x):\n",
    "#     return [func(t) for t in x] if isinstance(x, list) else func(x)\n",
    "\n",
    "# def remove_diacritics(x):\n",
    "#     return _map(unidecode, x)\n",
    "\n",
    "# def split_hyphens_and_slashes(x):\n",
    "#     return _map(lambda t: re.sub(r\"[-–—/]\", \" \", t), x)\n",
    "\n",
    "# def normalize_nums(x):\n",
    "#     return _map(lambda t: re.sub(r\"(\\d)[-–—-](\\d)\", r\"\\1-\\2\", t), x)\n",
    "\n",
    "# # ---------- your original jiwer transform ---------------------------\n",
    "# transform = Compose([\n",
    "#     ToLowerCase(),\n",
    "#     remove_diacritics,\n",
    "#     split_hyphens_and_slashes,\n",
    "#     normalize_nums,\n",
    "#     RemovePunctuation(),\n",
    "#     RemoveMultipleSpaces(),\n",
    "#     Strip(),\n",
    "#     ReduceToListOfListOfWords(),   # -> [[\"word\", ...], ...]\n",
    "# ])\n",
    "\n",
    "# def compute_wer(ref, hyp):\n",
    "#     return wer(\n",
    "#         ref, hyp,\n",
    "#         reference_transform=transform,\n",
    "#         hypothesis_transform=transform,\n",
    "#     )\n",
    "\n",
    "# # ---------- lightweight normaliser for term metrics -----------------\n",
    "# _punc_rx   = re.compile(r\"[^\\w\\s]\")\n",
    "# _range_rx  = re.compile(r\"(\\d)[-–—-](\\d)\")\n",
    "# _split_rx  = re.compile(r\"[-–—/]\")\n",
    "\n",
    "# def _normalise(text: str) -> str:\n",
    "#     text = unidecode(text.lower())\n",
    "#     text = _range_rx.sub(r\"\\1-\\2\", text)\n",
    "#     text = _split_rx.sub(\" \", text)\n",
    "#     text = _punc_rx.sub(\" \", text)\n",
    "#     return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "# def _term_recall(row, hyp_text):\n",
    "#     hyp_norm = _normalise(hyp_text)\n",
    "#     hits = sum(1 for t in row[\"medical_terms\"] if _normalise(t) in hyp_norm)\n",
    "#     return hits / len(row[\"medical_terms\"])\n",
    "\n",
    "# def _extract_term_tokens(row, text):\n",
    "#     tokens = _normalise(text).split()\n",
    "#     keep   = [False] * len(tokens)\n",
    "#     for term in row[\"medical_terms\"]:\n",
    "#         ttoks = _normalise(term).split()\n",
    "#         for i in range(len(tokens) - len(ttoks) + 1):\n",
    "#             if tokens[i:i+len(ttoks)] == ttoks:\n",
    "#                 for j in range(i, i+len(ttoks)):\n",
    "#                     keep[j] = True\n",
    "#     return \" \".join(tok for tok, flag in zip(tokens, keep) if flag)\n",
    "\n",
    "# # ---------- main evaluation routine ---------------------------------\n",
    "# def evaluate(df: pd.DataFrame) -> None:\n",
    "#     # ensure list[str] in medical_terms\n",
    "#     if isinstance(df[\"medical_terms\"].iloc[0], str):\n",
    "#         df[\"medical_terms\"] = df[\"medical_terms\"].apply(ast.literal_eval)\n",
    "\n",
    "#     # Global WER (your existing metric)\n",
    "#     df[\"wer_vanilla\"] = df.apply(\n",
    "#         lambda r: compute_wer(r[\"reference\"], r[\"vanilla\"]), axis=1)\n",
    "#     df[\"wer_fused\"]   = df.apply(\n",
    "#         lambda r: compute_wer(r[\"reference\"], r[\"fused\"]), axis=1)\n",
    "\n",
    "#     # Medical-Term Recall\n",
    "#     df[\"mtr_vanilla\"] = df.apply(\n",
    "#         lambda r: _term_recall(r, r[\"vanilla\"]), axis=1)\n",
    "#     df[\"mtr_fused\"]   = df.apply(\n",
    "#         lambda r: _term_recall(r, r[\"fused\"]), axis=1)\n",
    "\n",
    "#     # Medical-Term-only WER\n",
    "#     df[\"mtwer_vanilla\"] = df.apply(\n",
    "#         lambda r: wer(\n",
    "#             _extract_term_tokens(r, r[\"reference\"]),\n",
    "#             _extract_term_tokens(r, r[\"vanilla\"]),\n",
    "#             reference_transform=transform,\n",
    "#             hypothesis_transform=transform), axis=1)\n",
    "#     df[\"mtwer_fused\"]   = df.apply(\n",
    "#         lambda r: wer(\n",
    "#             _extract_term_tokens(r, r[\"reference\"]),\n",
    "#             _extract_term_tokens(r, r[\"fused\"]),\n",
    "#             reference_transform=transform,\n",
    "#             hypothesis_transform=transform), axis=1)\n",
    "\n",
    "#     # -------- summary printout --------------------------------------\n",
    "#     print(\"\\n=== Global WER ===\")\n",
    "#     print(f\"  vanilla : {df['wer_vanilla'].mean():.4f}\")\n",
    "#     print(f\"  fused   : {df['wer_fused'].mean():.4f}\")\n",
    "\n",
    "#     print(\"\\n=== Medical-Term Recall ===\")\n",
    "#     print(f\"  vanilla : {df['mtr_vanilla'].mean():.4f}\")\n",
    "#     print(f\"  fused   : {df['mtr_fused'].mean():.4f}\")\n",
    "\n",
    "#     print(\"\\n=== Medical-Term-only WER ===\")\n",
    "#     print(f\"  vanilla : {df['mtwer_vanilla'].mean():.4f}\")\n",
    "#     print(f\"  fused   : {df['mtwer_fused'].mean():.4f}\")\n",
    "\n",
    "# # ---------- run on your DataFrame -----------------------------------\n",
    "\n",
    "# import pandas as pd \n",
    "\n",
    "# results_df = pd.DataFrame(\n",
    "#     {\n",
    "#         \"vanilla\":[i.strip() for i in vanilla], \n",
    "#         \"fused\":[i.strip() for i in fused], \n",
    "#         \"reference\":ds['text'],\n",
    "#         \"medical_terms\":ds['medical_terms']\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# evaluate(results_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db16fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import LogitsProcessor, LogitsProcessorList\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class ShallowFusion(LogitsProcessor):\n",
    "#     def __init__(self, lm, shared_vocab, eos, alpha=0.3, warmup_steps=3):\n",
    "#         super().__init__()\n",
    "#         self.lm = lm.eval().requires_grad_(False)\n",
    "#         self.V = shared_vocab\n",
    "#         self.eos = eos\n",
    "#         self.alpha = alpha\n",
    "#         self.warmup = warmup_steps\n",
    "#         self.step = 0\n",
    "\n",
    "#     @torch.no_grad()\n",
    "#     def __call__(self, input_ids, scores):\n",
    "#         print('printing input_ids.size(), scores.size(), step, input_ids, dec_ids')\n",
    "#         print(input_ids.size(), scores.size(), self.step, input_ids, processor.batch_decode(input_ids))\n",
    "#         self.step+=1 \n",
    "\n",
    "#         return scores\n",
    "    \n",
    "# fusion_proc = ShallowFusion(\n",
    "#     lm=gpt2,\n",
    "#     shared_vocab=gpt2.config.vocab_size,\n",
    "#     eos=EOS_ID,\n",
    "#     alpha=0.3\n",
    "# )\n",
    "\n",
    "# batch = next(iter(loader))\n",
    "# feats = batch['input_features'].to(DEVICE)\n",
    "# masks = batch['attention_mask'].to(DEVICE)\n",
    "\n",
    "# with torch.no_grad():\n",
    "\n",
    "#     out1 = whisper.generate(\n",
    "#         input_features=feats,\n",
    "#         attention_mask=masks,\n",
    "#         logits_processor=LogitsProcessorList([fusion_proc]),\n",
    "#         return_dict_in_generate=True,\n",
    "#         output_scores=True,\n",
    "#         num_beams=2,\n",
    "#     )\n",
    "\n",
    "#     # out2 = whisper.generate(\n",
    "#     #     input_features=feats,\n",
    "#     #     attention_mask=masks,\n",
    "#     #     return_dict_in_generate=True,\n",
    "#     #     output_scores=True,\n",
    "#     #     num_beams=2\n",
    "#     # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14230833",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))\n",
    "feats = batch['input_features'].to(DEVICE)\n",
    "masks = batch['attention_mask'].to(DEVICE)\n",
    "\n",
    "# Generate to get sequences\n",
    "with torch.no_grad():\n",
    "    out = whisper.generate(\n",
    "        input_features=feats,\n",
    "        attention_mask=masks,\n",
    "        num_beams=1,\n",
    "        do_sample=False,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        max_new_tokens=5\n",
    "    )\n",
    "# Compare step 0\n",
    "decoder_ids = out.sequences[:,0:-1]  # Just the start token\n",
    "with torch.no_grad():\n",
    "    direct_logits = whisper(feats, decoder_input_ids=decoder_ids).logits[:, -1, :].to(DEVICE)\n",
    "    direct_lp = torch.log_softmax(direct_logits, dim=-1)\n",
    "\n",
    "gen_lp = out.scores[-1].to(DEVICE)\n",
    "\n",
    "print(gen_lp)\n",
    "print(direct_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4d3e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd359960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter truly out of bounds vocab >=EOS\n",
    "oob_mask = decoder_ids > EOS_ID # create mask for gpt2 OOV tokens emitted by whisper\n",
    " # replace with gpt2 pad token\n",
    "filtered = decoder_ids.masked_fill(oob_mask, gpt2_tok.pad_token_id)\n",
    "attention_mask = (filtered != gpt2_tok.pad_token_id).long()\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits_new = gpt2(input_ids=filtered, attention_mask=attention_mask).logits[:,-1, :]\n",
    "\n",
    "# because we dont want gpt2 to impact or determine termination just ASR model\n",
    "logits_new[:,:EOS_ID-1].size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
