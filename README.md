# Shallow Fusion Eval/POC

An integration and evaluation repository for testing shallow fusion techniques on medical domain ASR (Automatic Speech Recognition). Read the full motivation and technical details [**‚ú®üëâ HERE üëà‚ú®**](https://donkeyanaphora.github.io/articles/article1/index.html)

## Overview

This proof-of-concept explores shallow fusion methods to improve medical transcription quality by combining acoustic and language models. The project aims to reduce Word Error Rate (WER) for medical terminology while maintaining overall transcription quality. For details on the model pretraining please refer to the model cards or the repo for the finetuning pipeline

## Related Resources
**Fine tuning pipeline and model cards**:

[![View on GitHub](https://img.shields.io/badge/View%20on-GitHub-181717?logo=github)](https://github.com/donkeyanaphora/SHALLOW_FUSION)

[![Hugging Face Models](https://img.shields.io/badge/HuggingFace-Models-orange?logo=huggingface)](https://huggingface.co/cwestnedge/models) 


## Current Status

### Active Development
1. **Fusion Codebase Enhancement** - Optimizing for faster inference and seamless HuggingFace integration
2. **Metrics Development** - Creating granular error analysis tools to decompose error types
3. **Evaluation Pipeline** - Testing on larger medical ASR datasets beyond synthetic POC data

## Project Structure

```
shallow-fusion-eval/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ input/      # POC text data
‚îÇ   ‚îî‚îÄ‚îÄ output/     # Generated .wav files
‚îú‚îÄ‚îÄ scripts/        # TTS conversion utilities
‚îú‚îÄ‚îÄ notebooks/      # Fusion implementation & evaluation
‚îî‚îÄ‚îÄ README.md
```

## Setup

*Documentation in progress*

## Data Sources

### Current Implementation
- **Synthetic dataset**: Text-to-speech generated audio-transcript pairs for initial testing

### Planned Data Sources
Real medical transcription datasets under consideration:

- [Shaip - Physician Dictation Data: Radiology](https://marketplace.databricks.com/details/8eb39dd5-ffc4-4e8d-8f89-25d91bf1774b/Shaip_Physician-Dictation-Data-Radiology)
- [John Snow Labs - Medical Transcription](https://marketplace.databricks.com/details/cd0b8356-8ae8-4178-a55b-7f69f040c0b8/John-Snow-Labs_Medical-Transcription)
- [Galileo - Medical Transcript 40](https://huggingface.co/datasets/galileo-ai/medical_transcription_40/viewer/default/train?row=0&views%5B%5D=train)

## Roadmap

### Core Challenge
Balancing improved WER for medical terminology against potential performance degradation on conversational elements when increasing the fusion parameter Œ±.

### Technical Improvements

**Completed:**
- [‚úîÔ∏è] Build custom logits processor for fusion
- [‚úîÔ∏è] Beam search support (part of the logits processor work) ([reference](https://huggingface.co/blog/mlabonne/decoding-strategies))
- [‚úîÔ∏è] Prompt engineering for domain adaptation with GPT-2
- [‚úîÔ∏è] Normalize WER metric
- [‚úîÔ∏è] Handle punctuation mismatches in evaluation sets
- [‚úîÔ∏è] Replace deprecated original dataset

**In Progress:**
- [‚è≥] Evaluate on non-synthetic (Shaip Radiology Dictations)
- [‚è≥] Cache `past_key_values` to avoid redundant encoder passes
- [‚è≥] Develop adaptive gating mechanism for context-aware decoder influence
- [‚è≥] Coverage penalty term for early terminations (self attention step)
- [‚ùå] Fine-tune on conversational text (~10,000 samples) if needed

## Notes
This is an active research project. The main concern is improving WER for medical terms while managing performance on conversational filler terms that may be absent in the external LMs' pre-training data.